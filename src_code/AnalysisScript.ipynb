{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d2c4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from labellines import labelLine, labelLines\n",
    "from custom_model.predictor import *\n",
    "from custom_model.losses import *\n",
    "from custom_model.datagen import *\n",
    "from custom_model.inference import *\n",
    "from custom_model.inference_hist import EnsemblePrediction, Calibration\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.optimizers import Adam\n",
    "import os\n",
    "from scipy.stats import beta\n",
    "from scipy.stats import moment\n",
    "\n",
    "from config import *\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "tf.get_logger().setLevel('INFO')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0661c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "para['normalize'] = 0 # DO NOT normalize\n",
    "testin_gen = DataGenerator(para, 8, 'testin') # test-2019\n",
    "testout_gen = DataGenerator(para, 8, 'testout') # test-2022\n",
    "\n",
    "# get ground-truth of both test sets\n",
    "x1 = testin_gen.x\n",
    "y1 = testin_gen.y\n",
    "\n",
    "x2 = testout_gen.x\n",
    "y2 = testout_gen.y\n",
    "\n",
    "# get parameters (a, b) of beta distributions predicted by the deep ensembles\n",
    "data1 = np.load('./result/2019.npz')\n",
    "a1 = data1['A']\n",
    "b1 = data1['B']\n",
    "\n",
    "data2 = np.load('./result/2022.npz')\n",
    "a2 = data2['A']\n",
    "b2 = data2['B']\n",
    "\n",
    "# calculate mean and variance\n",
    "mu1, var1 = beta.stats(a1, b1, scale=130, moments='mv')\n",
    "mu2, var2 = beta.stats(a2, b2, scale=130, moments='mv')\n",
    "\n",
    "# calculate two types of uncertainty measure by variance\n",
    "yp1 = np.mean(mu1, 0)\n",
    "alea1 = np.mean(var1, 0)\n",
    "epis1 = np.var(mu1, 0)\n",
    "\n",
    "yp2 = np.mean(mu2, 0)\n",
    "alea2 = np.mean(var2, 0)\n",
    "epis2 = np.var(mu2, 0)\n",
    "\n",
    "# calculate two types of uncertainty measure by entropy\n",
    "Ua1, Ue1 = EntropyUncertainty(a1, b1)\n",
    "Ua2, Ue2 = EntropyUncertainty(a2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90592d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot figure 6 in the manuscript\n",
    "Ua = np.zeros(10)\n",
    "Ue = np.zeros(10)\n",
    "Ut = np.zeros(10)\n",
    "for i in range(10):\n",
    "    Ua[i] = np.mean(alea2[:,i])**0.5\n",
    "    Ue[i] = np.mean(epis2[:,i])**0.5\n",
    "    Ut[i] = np.mean(epis2[:,i]+alea2[:,i])**0.5\n",
    "#     Ua[i] = np.mean(Ea1[:,i])\n",
    "#     Ue[i] = np.mean(Ee1[:,i])\n",
    "#     Ut[i] = np.mean(Ea1[:,i]+Ee1[:,i])\n",
    "plt.plot(np.arange(4,41,4), Ua, marker='+', label='aleatoric')\n",
    "plt.plot(np.arange(4,41,4), Ue, marker='x', label='epistemic')\n",
    "plt.plot(np.arange(4,41,4), Ut, marker='*', label='total', color='black')\n",
    "plt.xlabel('prediction horizon (min)', fontsize=14)\n",
    "plt.ylabel('entropy (nats)', fontsize=14)\n",
    "plt.xticks(np.arange(4,41,4))\n",
    "plt.xlim(0,44)\n",
    "#plt.ylim(-3,0.5)\n",
    "plt.grid(linestyle='-', color='lightgray')\n",
    "plt.legend(loc='best', fontsize=13)\n",
    "plt.title('Uncertainty by variance(2022)', fontsize=14)\n",
    "#plt.savefig('imgs/var_un2019.png', dpi=800)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d4f80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure 7\n",
    "fig, axes = plt.subplots(2,2,figsize=(10,10))\n",
    "#fig.tight_layout()\n",
    "axes[0,0].hist(np.mean(alea1,(1,2))**0.5, bins=50, alpha=0.3, density=True, label='2019', color='blue', edgecolor='grey')\n",
    "axes[0,0].hist(np.mean(alea2,(1,2))**0.5, bins=50, alpha=0.3, density=True, label='2022', color='red', edgecolor='grey')\n",
    "axes[0,0].set_xlim(0,20)\n",
    "axes[0,0].set_xlabel('$\\sigma$ (km/h)', fontsize=12)\n",
    "axes[0,0].set_ylabel('probability density', fontsize=12)\n",
    "axes[0,0].set_title('aleatoric (variance)', fontsize=12)\n",
    "\n",
    "axes[1,0].hist(np.mean(Ua1,(1,2)), bins=50, alpha=0.3, density=True, label='2019',color='blue', edgecolor='grey')\n",
    "axes[1,0].hist(np.mean(Ua2,(1,2)), bins=50, alpha=0.3, density=True, label='2022',color='red', edgecolor='grey')\n",
    "axes[1,0].set_xlim(-3.0,-0.5)\n",
    "axes[1,0].set_xlabel('Entropy (nats)', fontsize=12)\n",
    "axes[1,0].set_ylabel('probability density', fontsize=12)\n",
    "axes[1,0].set_title('aleatoric (entropy)', fontsize=12)\n",
    "\n",
    "axes[0,1].hist(np.mean(epis1,(1,2))**0.5, bins=50, alpha=0.3, density=True, label='2019',color='blue', edgecolor='grey')\n",
    "axes[0,1].hist(np.mean(epis2,(1,2))**0.5, bins=50, alpha=0.3, density=True, label='2022',color='red', edgecolor='grey')\n",
    "axes[0,1].set_xlim(0,10)\n",
    "axes[0,1].set_xlabel('$\\sigma$ (km/h)', fontsize=12)\n",
    "axes[0,1].set_title('epistemic (variance)', fontsize=12)\n",
    "\n",
    "axes[1,1].hist(np.mean(Ue1,(1,2)), bins=50, alpha=0.3, density=True, label='2019',color='blue', edgecolor='grey')\n",
    "axes[1,1].hist(np.mean(Ue2,(1,2)), bins=50, alpha=0.3, density=True, label='2022',color='red', edgecolor='grey')\n",
    "axes[1,1].set_xlim(0.05,0.45)\n",
    "axes[1,1].set_xlabel('Entropy (nats)', fontsize=12)\n",
    "axes[1,1].set_title('epistemic (entropy)', fontsize=12)\n",
    "axes[0,1].legend()\n",
    "\n",
    "fig.subplots_adjust(hspace=0.3)\n",
    "\n",
    "plt.savefig('imgs/metrics.jpg', dpi=800)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2f0002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure 8\n",
    "loc1=1\n",
    "loc2=50\n",
    "loc3=111\n",
    "fig, axes = plt.subplots(1, 3,figsize=(10,4))\n",
    "axes[0].scatter(yp1[:,4, loc1], alea1[:,4, loc1]**0.5, s=0.2, color='red')\n",
    "axes[0].set_xlim(20,120)\n",
    "axes[0].set_ylim(0,35)\n",
    "axes[0].set_ylabel('aleatoric $\\sigma$ (km/h)', fontsize=12)\n",
    "axes[0].set_xlabel('speed (km/h)', fontsize=12)\n",
    "axes[0].set_title('location-1', fontsize=12)\n",
    "\n",
    "axes[1].scatter(yp1[:,4, loc2], alea1[:,4, loc2]**0.5, s=0.2, color='blue')\n",
    "axes[1].set_xlim(20,120)\n",
    "axes[1].set_ylim(0,35)\n",
    "axes[1].set_xlabel('speed (km/h)', fontsize=12)\n",
    "axes[1].set_title('location-50', fontsize=12)\n",
    "\n",
    "axes[2].scatter(yp1[:,4, loc3], alea1[:,4, loc3]**0.5, s=0.2, color='orange')\n",
    "axes[2].set_xlim(20,120)\n",
    "axes[2].set_ylim(0,35)\n",
    "axes[2].set_xlabel('speed (km/h)', fontsize=12)\n",
    "axes[2].set_title('location-111', fontsize=12)\n",
    "\n",
    "plt.savefig('imgs/ushape.pdf', dpi=800)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
